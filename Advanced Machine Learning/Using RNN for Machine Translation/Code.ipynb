{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Code.ipynb","provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/05baddac9b2f50d639a62ea5fa6e21e4/torchtext_translation_tutorial.ipynb","timestamp":1603032474265}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"v_6g_yIgLj31"},"source":["Lab3 assignment\n","===================================\n","\n","To train the translator, we will do the following steps:\n","\n","1. Load the Multi30k datasets using ``torchtext``\n","2. Define a Reccurent Neural Network and a loss function\n","3. Train the network on the training data\n","4. Test the network on the test data"]},{"cell_type":"code","metadata":{"id":"PhD3u_2hLj3y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707233382,"user_tz":-540,"elapsed":23338,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"e5a6f3bb-7df8-4caf-dbb7-5ecdc08bacbf"},"source":["%matplotlib inline\n","!python -m spacy download en\n","!python -m spacy download de\n","!pip install torchtext==0.6.0\n","\n","from torchtext.datasets import Multi30k\n","from torchtext.data import Field, BucketIterator\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","\n","#We'll set the random seeds for deterministic results.\n","SEED = 1234\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Collecting de_core_news_sm==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n","\u001b[K     |████████████████████████████████| 14.9MB 400kB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.4)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n","Building wheels for collected packages: de-core-news-sm\n","  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=e1ceca3424cf5f01a7a3135e3e8bab8628b247b1432ab4d07a7b115714bf10dc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vusgxces/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n","Successfully built de-core-news-sm\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('de_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/de\n","You can now load the model via spacy.load('de')\n","Collecting torchtext==0.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 13.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.18.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Found existing installation: torchtext 0.3.1\n","    Uninstalling torchtext-0.3.1:\n","      Successfully uninstalled torchtext-0.3.1\n","Successfully installed sentencepiece-0.1.94 torchtext-0.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zX56kJekLj32"},"source":["## 1. Preparing the Data\n","\n","``torchtext`` has utilities for creating datasets that can be easily\n","iterated through for the purposes of creating a language translation\n","model. One key class is a\n","[`Field`](https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L64),\n","which specifies the way each sentence should be preprocessed, and another is the\n","`TranslationDataset` ; ``torchtext``\n","has several such datasets; in this exercise we'll use the\n","[`Multi30k dataset`](https://github.com/multi30k/dataset), which contains about\n","30,000 sentences (averaging about 13 words in length) in both English and German.\n","\n","The tokenization in this exercise is [`Spacy`](https://spacy.io).\n","We use Spacy because it provides strong support for tokenization in languages\n","other than English. The following code will tokenize each of the sentences\n","in the ``TranslationDataset`` based on the tokenizer defined in the ``Field``.\n","\n"]},{"cell_type":"code","metadata":{"id":"Tt8sF_M-Lj32","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707241218,"user_tz":-540,"elapsed":31131,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"2bdbce57-41c5-4355-f978-e50f322ba461"},"source":["SRC = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"de\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True)\n","\n","TRG = Field(tokenize = \"spacy\",\n","            tokenizer_language=\"en\",\n","            init_token = '<sos>',\n","            eos_token = '<eos>',\n","            lower = True)\n","\n","#Split training samples of 29,000, validation samples of 1,014 and testing samples of 1,000.\n","train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n","                                                    fields = (SRC, TRG))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rtraining.tar.gz:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"],"name":"stderr"},{"output_type":"stream","text":["downloading training.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 5.04MB/s]\n","validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.44MB/s]"],"name":"stderr"},{"output_type":"stream","text":["downloading validation.tar.gz\n","downloading mmt_task1_test2016.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["\n","mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.40MB/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ZfyPmm1NLj36"},"source":["Now that we've defined ``train_data``, we can see an extremely useful\n","feature of ``torchtext``'s ``Field``: the ``build_vocab`` method\n","now allows us to create the vocabulary associated with each language.\n","\n","Once these lines of code have been run, ``SRC.vocab.stoi`` will  be a\n","dictionary with the tokens in the vocabulary as keys and their\n","corresponding indices as values; ``SRC.vocab.itos`` will be the same\n","dictionary with the keys and values swapped. We won't make extensive\n","use of this fact in this tutorial, but this will likely be useful in\n","other NLP tasks you'll encounter.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoXM6pBplmAi","executionInfo":{"status":"ok","timestamp":1605707241220,"user_tz":-540,"elapsed":31125,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"be3393c7-76b5-4ed6-c12f-60d2f9120b9f"},"source":["print(len(train_data)) #number of training samples\n","print(len(valid_data)) #number of validation samples\n","print(len(test_data)) #number of testing samples"],"execution_count":null,"outputs":[{"output_type":"stream","text":["29000\n","1014\n","1000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H8t7-3n9Lj36"},"source":["SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aO5ZzN-uLj39"},"source":["\n","The last ``torchtext`` specific feature we'll use is the ``BucketIterator``,\n","which is easy to use since it takes a ``TranslationDataset`` as its\n","first argument. Specifically, as the docs say:\n","Defines an iterator that batches examples of similar lengths together.\n","Minimizes amount of padding needed while producing freshly shuffled\n","batches for each new epoch. See pool for the bucketing procedure used.\n","\n"]},{"cell_type":"code","metadata":{"id":"WZ0IgHTpLj39"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE = 1024\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    device = device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-VLRBY6RFKpn"},"source":["## 2. Build the Transformer Model"]},{"cell_type":"code","metadata":{"id":"erEuVycw26p-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707252236,"user_tz":-540,"elapsed":42128,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"6f79a991-d174-4a75-9bf7-3ec287fbac67"},"source":["from torch.nn import Transformer\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken_in, ntoken_out, ninp, nhead, npf_dim, nlayers, src_pad_idx, trg_pad_idx, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","\n","        # --------------- param -----------------\n","        # ntoken_in: the idx of the input word after tokenization \n","        # ntoken_out: the idx of the input word w.r.t. the tokenization \n","        # ninp: the number of expected features in the encoder/decoder inputs \n","        # nhead: the number of multiAttention heads \n","        # npf_dim: the dimension of the feedforward layer \n","        # src_pad_idx: the token for padding in source language\n","        # trg_pad_idx: the token for padding in target language \n","        # ----------------------------------------\n","\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        self.transformer = Transformer(d_model=ninp, nhead=nhead, num_encoder_layers=nlayers, num_decoder_layers=nlayers,\n","                                       dim_feedforward=npf_dim, dropout=dropout, activation='relu')\n","      \n","        self.encoder_en = nn.Embedding(ntoken_in, ninp)  # tok_embedding for input \n","        self.encoder_de = nn.Embedding(ntoken_out, ninp) # tok_embedding for output \n","        self.ninp = ninp\n","        self.decoder = nn.Linear(ninp, ntoken_out)\n","\n","        self.src_pad_idx = src_pad_idx\n","        self.tgt_pad_idx = trg_pad_idx\n","\n","        self.init_weights()\n","\n","    def _generate_src_key_mask(self, src):\n","        # for key_padding_mask in transformer\n","        # the positions with the value of True will be ignored while the position\n","        # with the value of False will be unchanged. We mask all padding words. \n","        # The output dim is b*s\n","        src_mask = (src == self.src_pad_idx)\n","        return src_mask.T\n","\n","    def _generate_tgt_mask(self, tgt, sz):\n","        # Beside key_padding_mask in transformer, the output or teacher input \n","        # should be masked sequentially to prevent the model get any information \n","        # from the future words it is going to predict \n","        tgt_key_mask = tgt == self.tgt_pad_idx\n","\n","        # We provide FloatTensor attn_mask. It will be added to the attention weight.\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        attn_mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).to(tgt.device)\n","        return attn_mask, tgt_key_mask.T\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder_en.weight.data.uniform_(-initrange, initrange)\n","        self.encoder_de.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, tgt):\n","        # src\n","        src_key_mask = self._generate_src_key_mask(src)\n","        src = self.encoder_en(src) * math.sqrt(self.ninp)  # use a learned encoder put stoi index to a feature space s*b --> s*b*e\n","        src = self.pos_encoder(src)  # add the pos feature toward feature space\n","\n","        # tgt\n","        tgt_mask, tgt_key_mask = self._generate_tgt_mask(tgt, tgt.size(0))\n","        tgt = self.encoder_de(tgt) * math.sqrt(self.ninp) \n","        tgt = self.pos_encoder(tgt)\n","\n","        output = self.transformer(src, tgt, tgt_mask=tgt_mask, \n","                                  src_key_padding_mask = src_key_mask, \n","                                  tgt_key_padding_mask = tgt_key_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","class PositionalEncoding(nn.Module):\n","    # The positional encoding as described in the paper \n","    # https://arxiv.org/pdf/1706.03762.pdf\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","# Here we intialize our model\n","INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","print(INPUT_DIM, OUTPUT_DIM)\n","\n","HID_DIM = 256\n","N_LAYERS = 3\n","N_HEADS = 8\n","N_PF_DIM = 512\n","DROPOUT = 0.1\n","\n","SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","model =TransformerModel(ntoken_in = INPUT_DIM, ntoken_out=OUTPUT_DIM, ninp=HID_DIM, \n","                        nhead=N_HEADS, npf_dim=N_PF_DIM, nlayers=N_LAYERS,\n","                        src_pad_idx=SRC_PAD_IDX, trg_pad_idx=TRG_PAD_IDX, dropout=DROPOUT).to(device)\n","\n","def count_parameters(model: nn.Module):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')\n","\n","def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.xavier_uniform_(m.weight.data)\n","\n","model.apply(initialize_weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7855 5893\n","The model has 8,988,677 trainable parameters\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["TransformerModel(\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (transformer): Transformer(\n","    (encoder): TransformerEncoder(\n","      (layers): ModuleList(\n","        (0): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","        (2): TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): TransformerDecoder(\n","      (layers): ModuleList(\n","        (0): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","        (1): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","        (2): TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): _LinearWithBias(in_features=256, out_features=256, bias=True)\n","          )\n","          (linear1): Linear(in_features=256, out_features=512, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=512, out_features=256, bias=True)\n","          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (encoder_en): Embedding(7855, 256)\n","  (encoder_de): Embedding(5893, 256)\n","  (decoder): Linear(in_features=256, out_features=5893, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"zjR1IR_A2HmB"},"source":["if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4iEav7eEh8Mg"},"source":["## 3. Training the Model\n","\n","We define our optimizer, which we use to update our parameters in the training loop. Here, we'll use Adam."]},{"cell_type":"code","metadata":{"id":"sjE6t32mh8Mg"},"source":["optimizer = optim.Adam(model.parameters(), lr=0.00085)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZtKHAS0qLj4C"},"source":["Next, we define our loss function. \n","\n","Note: when scoring the performance of a language translation model in\n","particular, we have to tell the ``nn.CrossEntropyLoss`` function to\n","ignore the indices where the target is simply padding.\n","\n"]},{"cell_type":"code","metadata":{"id":"-CmH9nJkLj4D"},"source":["PAD_IDX = TRG.vocab.stoi['<pad>']\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4FEJXl7DLj4H"},"source":["Finally, we can train and evaluate this model:\n"]},{"cell_type":"code","metadata":{"id":"9m3FhLDLLj4I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707491863,"user_tz":-540,"elapsed":281732,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"6d163d9f-46ef-4342-95f3-98c5e7c4c5de"},"source":["def train(model: nn.Module,\n","          iterator: BucketIterator,\n","          optimizer: optim.Optimizer,\n","          criterion: nn.Module,\n","          clip: float):\n","\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for _, batch in enumerate(iterator):\n","\n","        src = batch.src\n","        trg = batch.trg\n","        \n","        #remove the eos_token from the target sequence before giving it to the model as input.\n","        trg_temp = trg[:-1]\n","\n","        optimizer.zero_grad()\n","\n","        output = model(src, trg_temp)\n","\n","        output = output.view(-1, output.shape[-1])\n","        trg = trg[1:].view(-1)\n","\n","        loss = criterion(output, trg)\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def evaluate(model: nn.Module,\n","             iterator: BucketIterator,\n","             criterion: nn.Module):\n","\n","    #Evaluation mode\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for _, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","            trg_temp = trg[:-1]\n","            \n","            output = model(src, trg_temp)\n","\n","            output = output.view(-1, output.shape[-1])\n","            trg = trg[1:].view(-1)\n","\n","            loss = criterion(output, trg)\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def epoch_time(start_time: int,\n","               end_time: int):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","\n","\n","N_EPOCHS = 20\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 12s\n","\tTrain Loss: 6.112 | Train PPL: 451.392\n","\t Val. Loss: 5.000 |  Val. PPL: 148.352\n","Epoch: 02 | Time: 0m 12s\n","\tTrain Loss: 4.632 | Train PPL: 102.767\n","\t Val. Loss: 4.030 |  Val. PPL:  56.288\n","Epoch: 03 | Time: 0m 11s\n","\tTrain Loss: 3.882 | Train PPL:  48.529\n","\t Val. Loss: 3.607 |  Val. PPL:  36.838\n","Epoch: 04 | Time: 0m 11s\n","\tTrain Loss: 3.550 | Train PPL:  34.812\n","\t Val. Loss: 3.383 |  Val. PPL:  29.468\n","Epoch: 05 | Time: 0m 11s\n","\tTrain Loss: 3.284 | Train PPL:  26.671\n","\t Val. Loss: 3.120 |  Val. PPL:  22.655\n","Epoch: 06 | Time: 0m 11s\n","\tTrain Loss: 2.993 | Train PPL:  19.935\n","\t Val. Loss: 2.813 |  Val. PPL:  16.657\n","Epoch: 07 | Time: 0m 12s\n","\tTrain Loss: 2.619 | Train PPL:  13.716\n","\t Val. Loss: 2.464 |  Val. PPL:  11.749\n","Epoch: 08 | Time: 0m 11s\n","\tTrain Loss: 2.254 | Train PPL:   9.526\n","\t Val. Loss: 2.161 |  Val. PPL:   8.676\n","Epoch: 09 | Time: 0m 11s\n","\tTrain Loss: 1.954 | Train PPL:   7.058\n","\t Val. Loss: 1.973 |  Val. PPL:   7.193\n","Epoch: 10 | Time: 0m 11s\n","\tTrain Loss: 1.725 | Train PPL:   5.613\n","\t Val. Loss: 1.861 |  Val. PPL:   6.431\n","Epoch: 11 | Time: 0m 11s\n","\tTrain Loss: 1.550 | Train PPL:   4.714\n","\t Val. Loss: 1.777 |  Val. PPL:   5.911\n","Epoch: 12 | Time: 0m 11s\n","\tTrain Loss: 1.406 | Train PPL:   4.080\n","\t Val. Loss: 1.735 |  Val. PPL:   5.670\n","Epoch: 13 | Time: 0m 11s\n","\tTrain Loss: 1.283 | Train PPL:   3.608\n","\t Val. Loss: 1.710 |  Val. PPL:   5.529\n","Epoch: 14 | Time: 0m 12s\n","\tTrain Loss: 1.182 | Train PPL:   3.260\n","\t Val. Loss: 1.698 |  Val. PPL:   5.463\n","Epoch: 15 | Time: 0m 11s\n","\tTrain Loss: 1.094 | Train PPL:   2.987\n","\t Val. Loss: 1.690 |  Val. PPL:   5.417\n","Epoch: 16 | Time: 0m 11s\n","\tTrain Loss: 1.018 | Train PPL:   2.769\n","\t Val. Loss: 1.705 |  Val. PPL:   5.504\n","Epoch: 17 | Time: 0m 12s\n","\tTrain Loss: 0.946 | Train PPL:   2.575\n","\t Val. Loss: 1.695 |  Val. PPL:   5.448\n","Epoch: 18 | Time: 0m 12s\n","\tTrain Loss: 0.881 | Train PPL:   2.413\n","\t Val. Loss: 1.701 |  Val. PPL:   5.478\n","Epoch: 19 | Time: 0m 11s\n","\tTrain Loss: 0.830 | Train PPL:   2.293\n","\t Val. Loss: 1.718 |  Val. PPL:   5.573\n","Epoch: 20 | Time: 0m 12s\n","\tTrain Loss: 0.772 | Train PPL:   2.165\n","\t Val. Loss: 1.733 |  Val. PPL:   5.659\n","| Test Loss: 1.778 | Test PPL:   5.917 |\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nfDwsKB2Lj4M"},"source":["## 4. Inference and BLEU Score\n","\n","Network testing"]},{"cell_type":"code","metadata":{"id":"VralVbaE9Sch"},"source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","\n","    #Evaluation mode\n","    model.eval()\n","        \n","    if isinstance(sentence, str):\n","        nlp = spacy.load('de')\n","        tokens = [token.text.lower() for token in nlp(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","\n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","\n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","    src_key_mask = model._generate_src_key_mask(src_tensor)\n","    src_tensor = model.encoder_en(src_tensor) * math.sqrt(model.ninp)\n","    src_tensor = model.pos_encoder(src_tensor)\n","\n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","    trg_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","\n","    for i in range(max_len):\n","\n","        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(1).to(device)\n","\n","        with torch.no_grad():\n","            tgt_mask, tgt_key_mask = model._generate_tgt_mask(trg_tensor, trg_tensor.size(0))\n","            trg_tensor = model.encoder_de(trg_tensor) * math.sqrt(model.ninp)\n","            trg_tensor = model.pos_encoder(trg_tensor)\n","\n","            output = model.transformer(src_tensor, trg_tensor, tgt_mask=tgt_mask,\n","                                       src_key_padding_mask = src_key_mask,\n","                                       tgt_key_padding_mask = tgt_key_mask)\n","        \n","        output = model.decoder(output)\n","\n","        output = output[-1].view(-1, output.shape[-1])\n","        #pick the index with the highest probability as output.\n","        pred_token = output.argmax(1).item()\n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","    \n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","    \n","    return trg_tokens[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Abxemyiq_VNm"},"source":["Now, we'll grab some translations from our training set and see how well our model did. "]},{"cell_type":"code","metadata":{"id":"pbJVEnlI_ZLR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707491866,"user_tz":-540,"elapsed":281721,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"bcd29781-89e2-44e8-c0dd-4dd23794540f"},"source":["example_idx = 18\n","\n","src = vars(train_data.examples[example_idx])['src']\n","trg = vars(train_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["src = ['fünf', 'personen', 'sitzen', 'mit', 'instrumenten', 'im', 'kreis', '.']\n","trg = ['five', 'people', 'are', 'sitting', 'in', 'a', 'circle', 'with', 'instruments', '.']\n","predicted trg = ['five', 'people', 'are', 'sitting', 'in', 'a', 'circle', 'with', 'instruments', 'in', 'a', 'circle', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gei3uFajAcV8"},"source":["Next, let's get an example from the test set."]},{"cell_type":"code","metadata":{"id":"CxnrraGeAeBT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707491867,"user_tz":-540,"elapsed":281714,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"33198fe7-6cf1-4527-9b73-0b4a133efc9e"},"source":["example_idx = 10\n","\n","src = vars(test_data.examples[example_idx])['src']\n","trg = vars(test_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["src = ['eine', 'mutter', 'und', 'ihr', 'kleiner', 'sohn', 'genießen', 'einen', 'schönen', 'tag', 'im', 'freien', '.']\n","trg = ['a', 'mother', 'and', 'her', 'young', 'song', 'enjoying', 'a', 'beautiful', 'day', 'outside', '.']\n","predicted trg = ['a', 'mother', 'and', 'her', 'son', 'enjoying', 'a', 'nice', 'day', 'outside', 'in', 'the', 'beautiful', 'day', '.', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KZWirb8wB_az"},"source":["We define a calculate_bleu function which calculates the BLEU score over a provided TorchText dataset. This function creates a corpus of the actual and predicted translation for each source sentence and then calculates the BLEU score."]},{"cell_type":"code","metadata":{"id":"wGoioGI_CI3s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605707613287,"user_tz":-540,"elapsed":403127,"user":{"displayName":"Daniel Gwak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4FSGzeRk6uQDHtNktqDTV4A8o30n0ewJ7gOlB=s64","userId":"13581691481666858069"}},"outputId":"fca3b376-8553-47c1-9f73-187118388791"},"source":["from torchtext.data.metrics import bleu_score\n","\n","def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n","    \n","    #Evaluation mode\n","    model.eval()\n","    \n","    trgs = []\n","    pred_trgs = []\n","    \n","    for datum in data:\n","        \n","        src = vars(datum)['src']\n","        trg = vars(datum)['trg']\n","        \n","        pred_trg = translate_sentence(src, src_field, trg_field, model, device, max_len)\n","        \n","        #cut off <eos> token\n","        pred_trg = pred_trg[:-1]\n","        \n","        pred_trgs.append(pred_trg)\n","        trgs.append([trg])\n","        \n","    return bleu_score(pred_trgs, trgs)\n","\n","bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n","\n","#Target score is 35\n","print(f'BLEU score = {bleu_score*100:.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BLEU score = 35.21\n"],"name":"stdout"}]}]}